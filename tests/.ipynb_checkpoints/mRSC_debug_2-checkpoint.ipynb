{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from tslib.src import tsUtils\n",
    "from tslib.src.synthcontrol.syntheticControl import RobustSyntheticControl\n",
    "from tslib.src.synthcontrol.multisyntheticControl import MultiRobustSyntheticControl\n",
    "\n",
    "import random\n",
    "from numpy.linalg import svd, matrix_rank, norm\n",
    "from sklearn import linear_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hsvt(X, rank): \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: matrix of interest\n",
    "        rank: rank of output matrix\n",
    "    Output:\n",
    "        thresholded matrix\n",
    "    \"\"\"\n",
    "    u, s, v = np.linalg.svd(X, full_matrices=False)\n",
    "    s[rank:].fill(0)\n",
    "    return np.dot(u*s, v)\n",
    "\n",
    "def hsvt_df(X, rank): \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: matrix of interest\n",
    "        rank: rank of output matrix\n",
    "    Output:\n",
    "        thresholded matrix\n",
    "    \"\"\"\n",
    "    u, s, v = np.linalg.svd(X, full_matrices=False)\n",
    "    s[rank:].fill(0)\n",
    "    vals = (np.dot(u*s, v))\n",
    "    return pd.DataFrame(vals, index = X.index, columns = X.columns)\n",
    "\n",
    "def matrixFromSVD(sk, Uk, Vk, probability=1.0):\n",
    "    # Jehangir's\n",
    "    return (1.0/probability) * np.dot(Uk, np.dot(np.diag(sk), Vk.T))\n",
    "\n",
    "def hsvt_new(X, rank):\n",
    "    Uk, sk, Vk = np.linalg.svd(X, full_matrices=False)\n",
    "    Vk = Vk.T\n",
    "    sk[rank:].fill(0)\n",
    "    output = matrixFromSVD(sk, Uk, Vk, probability=1.0)\n",
    "    return output\n",
    "\n",
    "def hsvt_new_df(df, rank):\n",
    "    Uk, sk, Vk = np.linalg.svd(df.values, full_matrices=False)\n",
    "    Vk = Vk.T\n",
    "    sk[rank:].fill(0)\n",
    "    output = matrixFromSVD(sk, Uk, Vk, probability=1.0)\n",
    "    return pd.DataFrame(output, index=df.index, columns=df.columns)\n",
    "\n",
    "def get_preint_data(X, T0, T, K):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: N x KT matrix\n",
    "        T0: pre-int period\n",
    "        T: total period\n",
    "        K: number of metrics\n",
    "    \n",
    "    Output:\n",
    "        X_pre: N x KT0 matrix\n",
    "    \"\"\"\n",
    "    X_pre = np.array([])\n",
    "    for k in range(K): \n",
    "        if X.ndim > 1:\n",
    "            X_temp = X[:, k*T:k*T + T0]\n",
    "        else:\n",
    "            X_temp = X[k*T:k*T + T0]\n",
    "        X_pre = np.hstack([X_pre, X_temp]) if X_pre.size else X_temp\n",
    "    return X_pre\n",
    "\n",
    "def get_postint_data(X, T0, T, K):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: N x KT matrix\n",
    "        T0: pre-int period\n",
    "        T: total period\n",
    "        K: number of metrics\n",
    "    \n",
    "    Output:\n",
    "        X_post: N x K(T-T0) matrix\n",
    "    \"\"\"\n",
    "    X_post = np.array([])\n",
    "    for k in range(K): \n",
    "        if X.ndim > 1:\n",
    "            X_temp = X[:, k*T+T0:(k+1)*T]\n",
    "        else:\n",
    "            X_temp = X[k*T+T0:(k+1)*T]\n",
    "        X_post = np.hstack([X_post, X_temp]) if X_post.size else X_temp\n",
    "    return X_post\n",
    "\n",
    "\n",
    "def pre_post_split(y, T0, T, num_metrics):\n",
    "        y_pre = get_preint_data(y, T0, T, num_metrics)\n",
    "        y_post = get_postint_data(y, T0, T, num_metrics)\n",
    "        return y_pre, y_post\n",
    "\n",
    "\n",
    "def approximate_rank(X, t=99):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: matrix of interest\n",
    "        t: an energy threshold. Default (99%)\n",
    "        \n",
    "    Output:\n",
    "        r: approximate rank of Z\n",
    "    \"\"\"\n",
    "    u, s, v = np.linalg.svd(X, full_matrices=False)\n",
    "    total_energy = (100*(s**2).cumsum()/(s**2).sum())\n",
    "    r = list((total_energy>t)).index(True)+1\n",
    "    return r\n",
    "\n",
    "def relative_spectrum(X):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: matrix of interest\n",
    "        \n",
    "    Output:\n",
    "        list: with % of spectrum explained by first eigenvalues of Z\n",
    "    \"\"\"\n",
    "    u, s, v = np.linalg.svd(X, full_matrices=False)\n",
    "    return (s**2)/((s**2).sum())\n",
    "\n",
    "def donor_prep(X, t):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X: matrix of interest\n",
    "        t: threshold\n",
    "    \n",
    "    Output:\n",
    "        thresholded matrix\n",
    "    \"\"\"\n",
    "    r = approximate_rank(X, thresh)\n",
    "    print(\"{} SV = {}% of energy\".format(r, t))\n",
    "    X_hsvt = hsvt(X, r)\n",
    "    return np.abs(X_hsvt.round())\n",
    "\n",
    "def mse_df(y, y_pred):\n",
    "    # y, y_pred are df (2d)\n",
    "    return ((y - y_pred) ** 2).mean(axis=1)\n",
    "\n",
    "def rmse_df(y, y_pred):\n",
    "    # y, y_pred are df (2d)\n",
    "    return np.sqrt(((y - y_pred) ** 2).mean(axis=1))\n",
    "\n",
    "def mse(y, y_pred):\n",
    "    # y, ypred are 1d array\n",
    "    return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    # y, ypred are 1d array\n",
    "    return np.sqrt(mse(y,y_pred))\n",
    "\n",
    "def mape(y, y_pred):\n",
    "    mask = (y != 0)\n",
    "    return np.mean(np.abs((y - y_pred)[mask] / y[mask]))\n",
    "\n",
    "class mRSC:\n",
    "    def __init__(self, donor, target, metrics, donor_ids, target_ids, T_0s, singvals): \n",
    "        \"\"\"\n",
    "        donor = (df) donor matrix\n",
    "        target = (df) target_matrix\n",
    "        metrics = (list) list of metrics in donor/target matrix\n",
    "        donor_ids = (list) donor ids\n",
    "        target_ids = (list) target_ids\n",
    "        T_0s = (list)\n",
    "        singvals = (int) the number of singular values to keep; 0 if no HSVT\n",
    "        \"\"\"\n",
    "        if (singvals != 0):\n",
    "            self.donor = hsvt_new_df(donor, singvals)\n",
    "        else:\n",
    "            self.donor = donor\n",
    "        self.target = target\n",
    "        self.metrics = metrics\n",
    "        self.donor_ids = donor_ids\n",
    "        self.target_ids = target_ids\n",
    "        self.num_k = len(self.metrics)\n",
    "        self.T = int(self.target.shape[1]/self.num_k)\n",
    "        self.T_0s = T_0s\n",
    "        self.singvals = singvals\n",
    "        \n",
    "        \"\"\"\n",
    "        results are in a list of df's. df's.\n",
    "        list[0] corresponds to the first T_0\n",
    "        df's have target ids as index\n",
    "        \"\"\"\n",
    "        self.pred = [pd.DataFrame(columns=self.target.columns, index=self.target.index)] * len(T_0s)\n",
    "        self.betas = [pd.DataFrame(columns=self.donor.index, index=self.target.index)] * len(T_0s)\n",
    "#         self.mse_all = [pd.DataFrame(columns=range(num_k), index=self.target.index)] * len(T_0s)\n",
    "    \n",
    "    def learn(self, target_id, T_0, method='lr'):\n",
    "        # treatment unit\n",
    "        y = self.target[self.target.index == target_id]\n",
    "        y = y.values.flatten()\n",
    "\n",
    "        # pre-intervention\n",
    "        donor_pre = get_preint_data(self.donor.values, T_0, self.T, self.num_k)\n",
    "        y_pre = get_preint_data(y, T_0, self.T, self.num_k)\n",
    "\n",
    "        if (method == 'lr'):\n",
    "            # linear regression\n",
    "            regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "#             regr.n_jobs = -1\n",
    "            regr.fit(donor_pre.T, y_pre)\n",
    "            beta = regr.coef_\n",
    "            \n",
    "        elif (method == 'pinv'):\n",
    "            beta = np.linalg.pinv(donor_pre.T).dot(y_pre)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid method.\")\n",
    "        \n",
    "        i = np.where(np.array(self.T_0s) == T_0)[0][0]\n",
    "        \n",
    "        # beta\n",
    "        updated_beta = self.betas[i].copy()\n",
    "        updated_beta[updated_beta.index == target_id] = [beta]\n",
    "        self.betas[i] = updated_beta\n",
    "        \n",
    "        # prediction\n",
    "        prediction = self.donor.T.dot(beta).values\n",
    "        updated_pred = self.pred[i].copy()\n",
    "        updated_pred[updated_pred.index == target_id] = [prediction]\n",
    "        self.pred[i]= updated_pred\n",
    "        \n",
    "#         # mse\n",
    "#         mse_list = []\n",
    "#         for k in range(self.num_k):\n",
    "#             val = mse(y[self.T*k:self.T*(k+1)], prediction[self.T*k:self.T*(k+1)])\n",
    "#             mse_list.append(val)\n",
    "#         updated_mse = self.mse_all[i].copy()\n",
    "#         updated_mse[updated_mse.index == target_id] = [mse]\n",
    "#         self.mse_all[i] = updated_mse\n",
    "\n",
    "def getData(pre1, pre2, metrics, game_ids):\n",
    "    \"\"\"\n",
    "        pre1 = (string) target or donor\n",
    "        pre2 = (string) home or away\n",
    "        metrics = (list) list of metrics\n",
    "    \"\"\"\n",
    "    prefix = pre1+ \"_\" + pre2 + \"_\"\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(metrics)):\n",
    "        bucket = pd.read_pickle(\"../data/nba-hosoi/\"+ prefix +metrics[i]+\".pkl\")\n",
    "        df = pd.concat([df, bucket], axis = 1)\n",
    "    df = df[df.index.isin(game_ids)]\n",
    "    print(\"DataFrame size \", df.shape, \"was created.\")\n",
    "    return df\n",
    "\n",
    "# For Jehangir's Code\n",
    "def getDataForGit(pre1, pre2, metrics, game_ids):\n",
    "    \"\"\"\n",
    "        pre1 = (string) target or donor\n",
    "        pre2 = (string) home or away\n",
    "        metrics = (list) list of metrics\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    prefix = pre1+ \"_\" + pre2 + \"_\"\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(metrics)):\n",
    "        df = pd.read_pickle(\"../data/nba-hosoi/\"+ prefix +metrics[i]+\".pkl\")\n",
    "        df = df.iloc[df.index.isin(game_ids)].T\n",
    "        df = df.reset_index(drop=True)\n",
    "        df_list.append(df)\n",
    "    return df_list\n",
    "\n",
    "def getDF(donor_list, target_list, target_id):\n",
    "    # append the first column (target) before the donor dataframe\n",
    "    num_k = len(donor_list)\n",
    "    DF_list =[]\n",
    "    for k in range(num_k):\n",
    "        bucket = pd.concat([target_list[k][target_id], donor_list[k]], axis=1)\n",
    "        DF_list.append(bucket)\n",
    "    return DF_list\n",
    "\n",
    "def DF_split(DF_list, T_0):\n",
    "    # split train and test\n",
    "    num_k = len(DF_list)\n",
    "    DF_train_list =[]\n",
    "    DF_test_list =[]\n",
    "    for k in range(num_k):\n",
    "        X = DF_list[k]\n",
    "        train = X.iloc[:T_0,:]\n",
    "        test = X.iloc[T_0:,:]\n",
    "        DF_train_list.append(train)\n",
    "        DF_test_list.append(test)\n",
    "    return DF_train_list, DF_test_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playing with Jehangir's code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiment prarams\n",
    "train_pcts = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "freq = 15\n",
    "T = int(12*60*4/freq + 1)\n",
    "T_0s = [int(np.ceil(train_pct * T)) for train_pct in train_pcts]\n",
    "singvals = 1\n",
    "donor_ids = np.array(pd.read_pickle('../data/nba-hosoi/donor_ids.pkl'))\n",
    "target_ids = np.array(pd.read_pickle('../data/nba-hosoi/target_ids.pkl'))\n",
    "metrics = ['points','assists', 'rebounds', 'bs', 'fouls']\n",
    "num_k = len(metrics)\n",
    "relative_weights = [1.0] * len(T_0s)\n",
    "\n",
    "# data prep\n",
    "donor_home_list = getDataForGit(\"donor\", \"home\", metrics, donor_ids)\n",
    "target_home_list = getDataForGit(\"target\", \"home\", metrics, target_ids)\n",
    "\n",
    "donor_away_list = getDataForGit(\"donor\", \"away\", metrics, donor_ids)\n",
    "target_away_list = getDataForGit(\"target\", \"away\", metrics, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "singvals = 16\n",
    "target_id = target_ids[5]\n",
    "\n",
    "#################################################################\n",
    "keySeriesLabel = target_id\n",
    "otherSeriesLabels = donor_ids.tolist()\n",
    "\n",
    "# combine target (first row) + doner matrix\n",
    "DF_home_list = getDF(donor_home_list, target_home_list, target_id)\n",
    "DF_away_list = getDF(donor_away_list, target_away_list, target_id)\n",
    "\n",
    "\"\"\"first model with T_0 = 20\"\"\"\n",
    "T_0 = 20\n",
    "# train/test split\n",
    "DF_home_train_list, DF_home_test_list = DF_split(DF_home_list, T_0)     \n",
    "\n",
    "# model\n",
    "mrscmodel = MultiRobustSyntheticControl(num_k, relative_weights, keySeriesLabel, singvals, T_0, probObservation=1.0, svdMethod='numpy', otherSeriesKeysArray=otherSeriesLabels)\n",
    "\n",
    "# fit\n",
    "mrscmodel.fit(DF_home_train_list)\n",
    "\n",
    "\"\"\"second model with T_0 = 49\"\"\"\n",
    "T_0 = 49\n",
    "# train/test split\n",
    "DF_home_train_list, DF_home_test_list = DF_split(DF_home_list, T_0)     \n",
    "\n",
    "# model\n",
    "mrscmodel_1 = MultiRobustSyntheticControl(num_k, relative_weights, keySeriesLabel, singvals, T_0, probObservation=1.0, svdMethod='numpy', otherSeriesKeysArray=otherSeriesLabels)\n",
    "\n",
    "# fit\n",
    "mrscmodel_1.fit(DF_home_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.19107339e-16,   3.39134289e-01,   1.29543554e+00, ...,\n",
       "          1.20339881e+01,   1.19631550e+01,   1.19693739e+01],\n",
       "       [ -9.55990568e-17,   3.56293458e-01,   1.45391307e+00, ...,\n",
       "          2.05741648e+00,   1.88460253e+00,   2.03404726e+00],\n",
       "       [ -1.47727911e-16,   3.53351970e-01,   1.43178946e+00, ...,\n",
       "          7.41252206e+00,   7.71870347e+00,   8.21543649e+00],\n",
       "       ..., \n",
       "       [  1.55469948e-16,  -8.78899453e-02,  -2.75576598e-01, ...,\n",
       "          1.52760550e+01,   1.65945848e+01,   1.77469462e+01],\n",
       "       [  2.10076616e-16,  -1.35422222e-02,   2.85169138e-02, ...,\n",
       "          5.73209107e+00,   5.95184427e+00,   6.31410876e+00],\n",
       "       [  1.28979998e-16,   4.72481882e-01,   1.99943022e+00, ...,\n",
       "          1.13852553e+01,   1.18554517e+01,   1.22840998e+01]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrscmodel.model.matrix[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   2.,   2.,   4.,   4.,   4.,   4.,   4.,   6.,   8.,\n",
       "         8.,   8.,   8.,  10.,  10.,  10.,  12.,  12.,  12.,   1.,   1.,\n",
       "         1.,   2.,   2.,   2.,   2.,   3.,   3.,   3.,   3.,   3.,   4.,\n",
       "         4.,   4.,   5.,   5.,   5.,   5.,   5.,   0.,   0.,   0.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   3.,   3.,   4.,   4.,   4.,   5.,\n",
       "         5.,   5.,   5.,   5.,   5.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   1.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   3.,\n",
       "         3.,   3.,   3.,   0.,   0.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "         1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "         1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrscmodel.model.lastRowObservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mrscmodel.model.matrix[:,:20].round()\n",
    "b = mrscmodel.model.lastRowObservations[:20]\n",
    "np.flatnonzero((a == b).all(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "donor = mrscmodel_1.model.matrix[:-1,:]\n",
    "target = mrscmodel_1.model.lastRowObservations\n",
    "regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(donor.T, target)\n",
    "beta_lr = regr.coef_\n",
    "beta_pinv = np.linalg.pinv(donor.T).dot(target)\n",
    "beta_git = mrscmodel_1.model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4696780740939562e-18"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(beta_lr,beta_pinv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.539171387909769e-18"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(beta_pinv, beta_git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1520109154635949e-18"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(beta_lr, beta_git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr vs. pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size  (4738, 965) was created.\n",
      "DataFrame size  (4738, 965) was created.\n",
      "DataFrame size  (1179, 965) was created.\n",
      "DataFrame size  (1179, 965) was created.\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "\n",
    "# experiment prarams\n",
    "train_pcts = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "freq = 15\n",
    "T = int(12*60*4/freq + 1)\n",
    "T_0s = [int(np.ceil(train_pct * T)) for train_pct in train_pcts]\n",
    "singvals= 0\n",
    "donor_ids = np.array(pd.read_pickle('../data/nba-hosoi/donor_ids.pkl'))\n",
    "target_ids = np.array(pd.read_pickle('../data/nba-hosoi/target_ids.pkl'))\n",
    "metrics = ['points','assists', 'rebounds', 'bs', 'fouls']\n",
    "\n",
    "# import data\n",
    "donor_home = getData(\"donor\", \"home\", metrics, donor_ids)\n",
    "donor_away = getData(\"donor\", \"away\", metrics, donor_ids)\n",
    "\n",
    "target_home = getData(\"target\", \"home\", metrics, target_ids)\n",
    "target_away = getData(\"target\", \"away\", metrics, target_ids)\n",
    "\n",
    "\"\"\" lr \"\"\"\n",
    "# construct model\n",
    "mRSC_home_lr = mRSC(donor_home, target_home, metrics, donor_ids, target_ids, T_0s, singvals)\n",
    "mRSC_home_lr.learn(target_id, T_0, method='lr')\n",
    "\n",
    "\"\"\" pinv \"\"\"\n",
    "# construct model\n",
    "mRSC_home_pinv = mRSC(donor_home, target_home, metrics, donor_ids, target_ids, T_0s, singvals)\n",
    "mRSC_home_pinv.learn(target_id, T_0, method='pinv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21700652 :  1.53278487332e-17\n",
      "21700447 :  1.72050550576e-17\n",
      "21700419 :  9.35180997786e-18\n",
      "21700892 :  1.20002921811e-17\n",
      "21700256 :  1.17516246919e-17\n"
     ]
    }
   ],
   "source": [
    "# check for different target id's\n",
    "singvals = 16\n",
    "j=5\n",
    "T_0 = 20\n",
    "j_s = np.random.randint(0,1000,5)\n",
    "\n",
    "for j in j_s:\n",
    "\n",
    "    target_id = target_ids[j]\n",
    "    mRSC_home_lr.learn(target_id, T_0, method='lr')\n",
    "    mRSC_home_pinv.learn(target_id, T_0, method='pinv')\n",
    "\n",
    "    print(target_id,\": \", rmse(mRSC_home_pinv.betas[0].iloc[j,:].values, mRSC_home_lr.betas[0].iloc[j,:].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 :  1.17789102987e-17\n",
      "49 :  1.17789102987e-17\n",
      "97 :  1.17789102987e-17\n",
      "145 :  1.17789102987e-17\n",
      "174 :  1.17789102987e-17\n"
     ]
    }
   ],
   "source": [
    "# check for different T_0's\n",
    "singvals = 16\n",
    "j=5\n",
    "\n",
    "for T_0 in T_0s:\n",
    "    target_id = target_ids[j]\n",
    "    mRSC_home_lr.learn(target_id, T_0, method='lr')\n",
    "    mRSC_home_pinv.learn(target_id, T_0, method='pinv')\n",
    "\n",
    "    print(T_0,\": \", rmse(mRSC_home_pinv.betas[0].iloc[j,:].values, mRSC_home_lr.betas[0].iloc[j,:].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  1.17789102987e-17\n",
      "2 :  1.17789102987e-17\n",
      "4 :  1.17789102987e-17\n",
      "8 :  1.17789102987e-17\n",
      "16 :  1.17789102987e-17\n",
      "32 :  1.17789102987e-17\n",
      "50 :  1.17789102987e-17\n"
     ]
    }
   ],
   "source": [
    "# check for different singvals\n",
    "j=5\n",
    "T_0 = 20\n",
    "singvals_list = [1,2,4,8,16,32,50]\n",
    "for singvals in singvals_list:\n",
    "    target_id = target_ids[j]\n",
    "    mRSC_home_lr.learn(target_id, T_0, method='lr')\n",
    "    mRSC_home_pinv.learn(target_id, T_0, method='pinv')\n",
    "\n",
    "    print(singvals,\": \", rmse(mRSC_home_pinv.betas[0].iloc[j,:].values, mRSC_home_lr.betas[0].iloc[j,:].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
